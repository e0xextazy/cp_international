{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'oofs/'\n",
    "FILES = os.listdir(PATH)\n",
    "\n",
    "OOF = np.sort( [f for f in FILES if 'pkl' in f] )\n",
    "OOF_CSV = [pd.read_pickle(PATH+k).sort_values(by=['oid']) for k in OOF]\n",
    "\n",
    "print('We have %i oof files...'%len(OOF))\n",
    "print(); print(OOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(( len(OOF_CSV[0]),len(OOF), 13 ))\n",
    "y = np.zeros(( len(OOF_CSV[0]),len(OOF)))\n",
    "models = {}\n",
    "for k in range(len(OOF)):\n",
    "    models[k] = OOF[k]\n",
    "    for i in range(13):\n",
    "        x[:, k, i] = OOF_CSV[k][f\"pred_{i}\"].values\n",
    "    y[:,k] = OOF_CSV[k][\"category\"].values\n",
    "    \n",
    "x = softmax(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_trues, y_preds):\n",
    "    y_preds = np.argmax(y_preds, axis=-1)\n",
    "    counter = 0\n",
    "    for tr, pr in zip(y_trues, y_preds):\n",
    "        if tr == pr:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter -= 1\n",
    "    metric = counter / len(y_trues)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "for k in range(x.shape[1]): # по моделям\n",
    "    score = custom_score(y[:, k], x[:, k, :])\n",
    "    all.append(score)\n",
    "    print('Model %s has OOF score = %.4f'%(models[k], score))\n",
    "    \n",
    "m = [np.argmax(all)]; w = [] # argmin потому что с наименьшего скора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = np.max(all);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = 1000; \n",
    "PATIENCE = 1000; \n",
    "TOL = 0.000\n",
    "DUPLICATES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble custom_metric = %.4f by beginning with model %i %s'%(old,m[0], models[m[0]]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(len(OOF)):\n",
    "    \n",
    "    # BUILD CURRENT ENSEMBLE\n",
    "    md = x[:, m[0], :]\n",
    "    # print(md.shape)\n",
    "    for i,k in enumerate(m[1:]):\n",
    "        md = w[i]*x[:,k] + (1-w[i])*md\n",
    "        \n",
    "    # FIND MODEL TO ADD\n",
    "    mx = 0; mx_k = 0; mx_w = 0\n",
    "    print('Searching for best model to add... ')\n",
    "    \n",
    "    # TRY ADDING EACH MODEL\n",
    "    for k in range(x.shape[1]): # по моделям\n",
    "        print(k,', ',end='')\n",
    "        if not DUPLICATES and (k in m): continue\n",
    "            \n",
    "        # EVALUATE ADDING MODEL K WITH WEIGHTS W\n",
    "        bst_j = 0; bst = 0; ct = 0\n",
    "        for j in range(RES): # по порогу\n",
    "            tmp = j/RES * x[:, k, :] + (1-j/RES) * md\n",
    "            score = custom_score(y[:, k], tmp)\n",
    "            if score>bst:\n",
    "                bst = score\n",
    "                bst_j = j/RES\n",
    "            else: ct += 1\n",
    "            if ct>PATIENCE: break\n",
    "        print(bst)\n",
    "        if bst>mx:\n",
    "            mx = bst\n",
    "            mx_k = k\n",
    "            mx_w = bst_j\n",
    "            \n",
    "    # STOP IF INCREASE IS LESS THAN TOL\n",
    "    inc = mx-old\n",
    "    if inc<=TOL: \n",
    "        print(); print('No increase. Stopping.')\n",
    "        break\n",
    "        \n",
    "    # DISPLAY RESULTS\n",
    "    print();\n",
    "    print('Ensemble score = %.4f after adding model %i with weight %.3f. Increase of %.4f'%(mx,mx_k,mx_w,inc))\n",
    "    print()\n",
    "    \n",
    "    old = mx; m.append(mx_k); w.append(mx_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(weights):\n",
    "    weights_copy = weights.copy()\n",
    "    for i, w_i in enumerate(weights[:-1]):\n",
    "        for w_j in weights_copy[i+1:]:\n",
    "            weights[i] *= 1 - w_j\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = foo([1]+w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are using models',list(map(lambda x: str(x)+ \"_\" +models[x], m)))\n",
    "print('with weights',w)\n",
    "print('and achieve ensemble score = %.4f'%old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "x_all = np.zeros(x[:,0].shape)\n",
    "for model, weight in zip(m, w):\n",
    "    x_all += x[:, model] * weight\n",
    "    \n",
    "print(custom_score(x_all, y[:, 0]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
